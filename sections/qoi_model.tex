\section{QoI Model}
\label{sec:qoi_model}

%\begin{figure*}[t!]
%\centering
%    \subfigure[Top-K: Sum Similarity]{
%        \includegraphics[clip=true, trim = 17mm 65mm 25mm 70mm, scale=0.23]{figures/topk/topk_sum_sim_color.pdf}
%        \label{fig:topkSumSim}
%        }
%    \subfigure[Top-K: Avg. Match Target]{
%        \includegraphics[clip=true, trim = 17mm 65mm 25mm 70mm, scale=0.23]{figures/topk/avg_num_matching_color.pdf}
%        \label{fig:topkAvgNumSameSet}
%        }
%    \subfigure[Spanner: Sum Dissimilarity]{
%        \includegraphics[clip=true, trim = 17mm 65mm 25mm 70mm, scale=0.23]{figures/spanner/spannerCumulativeDist_color.pdf}
%        \label{fig:spanSumDissim}
%        }
%    \subfigure[Clustering: Cover All Sets]{
%        \includegraphics[clip=true, trim = 16mm 65mm 25mm 70mm, scale=0.23]{figures/cluster/perc_all_sets_covered_vary_k_color.pdf}
%        \label{fig:clusterAvgNumSetsCov}
%        }        
%   \caption{Completeness metrics for the three image selection algorithms. Each exhibits a diminishing return as more images are added.}
%   \label{fig:completeness_exp_results}
%\end{figure*}

QoI is a multi-dimensional metric that can be defined for an application to give a more meaningful measure of the value of information.  It consists of attributes such as  timeliness, freshness, completeness, accuracy, precision, etc.  
For example, information that contributes to a decision-making process may only be useful if it arrives before the decision must be made, or it may have varying usefulness based on how similar or dissimilar it is to other data already collected.

The specific details of which attributes are considered and how they contribute to QoI is application-dependent.  Chosen QoI metrics are stored as a vector associated with a data item.  
Here, as in \cite{qoi_aware_tactical_mil_nets}, we specify a vector of minimum values for each QoI metric, and 
information is evaluated based on whether it satisfies all of the QoI requirements or not.  We use this approach to establish the edges of QoI satisfiability for the vector of metrics, which defines the boundaries of maximum achievable QoI regions in the metric space.

We choose to use two QoI attributes, one that is time-based and one that is information-content-based.  The first attribute is timeliness, $T$, of data.  For the second attribute, we present a notion of \emph{completeness}, $C$, which we show can be defined multiple ways, depending on the application and context.  Together, a QoI requirement of $\mathbf{q} = \{C,T\}$ specifies a quantity of data that must be delivered as well as a deadline by which it must arrive to be useful.  Since completeness is a rather new concept, we explain an example image selection algorithm and show how it can be evaluated with completeness.
%REFERENCES THAT USE COMPLETENESS: 1) mentions completeness of information in context of mobile sensor networks; argues that mobility can increase coverage/completeness \cite{qoi_data_collection_mobile_sens_nets};  

\subsection{Example Application: Similarity-based Image Retrieval}

As a motivating example, we choose a network in which nodes store photographs that are to be exchanged or collected at one or more data sinks.  This example covers surveillance missions of military tactical networks or camera sensor networks.  In this model, nodes can act as both clients and servers, issuing queries and serving images in response.  Therefore, as the network size increases, the amount of traffic is also likely to increase, but possibly disproportionately.  This fact exemplifies why the problem of characterizing the scalability limits for an instance is not straightforward.

We give a very brief overview of an example application that relies on QoI. Details about the algorithms and metrics are in Appendix \ref{sec:image_retr_algs}.

Our example application allows a user to issue queries to collect images based on scores of similarity or dissimilarity, which provide contextually valuable information. An algorithm called {\bf Top-K} provides the $k$ most similar images to a given target image. For example, if a user has a picture of an unknown suspicious person entering a building, but the person is not identifiable from that image, it would be useful to collect more images that are similar to that one with the possibility that another picture may have a better view of the person in question that can be used for identification or more context. We use a metric called \emph{Sum Similarity}

In contrast, given the set of all photographs available in the network, we might want to return the set of $k$ images that exhibits the most diversity, ideally providing a user with a good sampling, or \emph{complete view}, of available images.  For instance, such a result would be quite useful in a surveillance mission.  We present two query algorithms that can be used to achieve this goal, {\bf Spanner} and {\bf Clustering}. The Spanner algorithm has an associated metric called \emph{Sum Dissimilarity}, and the Clustering algorithm can be evaluated by the probability that the returned set covers all distinct locations of interest. 

\subsection{Experimental Results}

To provide example values of these completeness metric definitions, experiments applying each query algorithm were run on a set of pictures taken at $n = 9$ different settings around the Penn State campus.  Each of these $9$ settings is of a pictorially different area, e.g. a particular building, a downtown street, or a lawn setting, and over $20$ images of each was taken.  Then, for individual trials, $10$ images from each set were randomly selected to create an image pool of $90$ pictures.  The three algorithms were run over these $90$ images, with the target image being randomly selected in the case of Top-K.  Results for each of the different completeness metrics were averaged over $1,000$ trials are shown in Figure \ref{fig:completeness_exp_results}. % Figures \ref{fig:topkSumSim} to \ref{fig:clusterAvgNumSetsCov}.

Figure \ref{fig:topkSumSim} shows the average sum similarity of images returned by the Top-K algorithm.  Figure \ref{fig:topkAvgNumSameSet} provides the second definition of completeness for the Top-K algorithm, the number of images matching the set that the target image was randomly chosen from.  
%Completeness results when dissimilarity is the objective are shown in Figures \ref{fig:spanSumDissim} and \ref{fig:clusterAvgNumSetsCov}.  Specifically, 
Figure \ref{fig:spanSumDissim} depicts the average Sum Dissimilarity returned by the Spanner algorithm, and Figure \ref{fig:clusterAvgNumSetsCov} represents the empirical probability of all $9$ sets being represented in the $k$ returned images.   For reference, we also include expected values for the metrics in Figures \ref{fig:topkAvgNumSameSet} and \ref{fig:clusterAvgNumSetsCov} if the images were selected from the entire image pool at random, i.e., without regard for image similarity or dissimilarity.  Details on these expected values given random selection are in Appendix \ref{sec:expl_exp_qoi}.

These figures exhibit the diminishing returns of completeness as more images are collected.  This effect visually shows how QoI differs from throughput.  As seen in these graphs, transmission of successive images does not result in a linear gain in completeness.  For example, in Figure \ref{fig:topkAvgNumSameSet}, it is evident that a value of only $k \approx 10$ is needed to collect $5$ images matching the target content, while collecting an additional $2$ from the same set usually requires collecting over twice that number of pictures.  
%For comparison, Figure \ref{fig:topkAvgNumSameSet} also shows the completeness achieved by random selection.
Similarly, Figure \ref{fig:clusterAvgNumSetsCov} shows that jumping from $k=10$ to $k=20$, the likelihood of capturing at least one image of every setting grows substantially from just over $10\%$ to approximately $90\%$.  To approach probabilities close to gaining that final $10\%$, however, requires a jump to $k\approx30$.  

The relationship between the number of images and completeness in each of these graphs also shows that obtaining a certain value of QoI or completeness requires a different number of images depending on the set available and their similarities.  We can denote the number of images required to achieve a level of completeness, $C$, as $k_{req} = Q(C)$.  This relationship will be useful later in determining capacity and scalability limits.

\subsection{Further Discussion of QoI}
We have defined and provided examples for a number of ways that completeness can be defined and used to obtain a concrete data requirement from a contextual QoI requirement.  Throughout the rest of the paper, we use sum similarity and the probability of covering all sets using clustering as completeness metrics, but we note that any of the definitions of completeness used here, or any other QoI requirement that can be translated into a data requirement, for that matter, can be used. 

%Also, while metadata associated with photographs may be useful in obtaining similar goals to those given in this section, relying on such information is problematic because metadata is not guaranteed to be available, and it is not as universally applicable as content-based retrieval.  For example, tags describing the image contents would require users to participate by entering this information, which is time-consuming and unreliable.  Location and time stamps may be automatically applied by the device allowing an application to filter images accordingly, but these tags often do not account for factors such as the direction of the camera or obstructed views.  Content-based processing, though, can be applied to any set of images.



